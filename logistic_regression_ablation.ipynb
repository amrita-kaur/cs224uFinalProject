{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# For sentiment analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Parts of speech\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"aita_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to have entirely numeric features\n",
    "# Change edited to 0 or 1\n",
    "# change pos/neg to 0 or 1\n",
    "# remove id, title, body, 0, 0.1\n",
    "data['edited'] = data['edited'].apply(lambda c: 0 if c == 'False' else 1)\n",
    "data['pos_neg'] = data['pos_neg'].apply(lambda c: 1 if c == 'pos' else 0)\n",
    "# remove id, title, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "data[\"gendered\"] = \"n\"\n",
    "for index,row in data.iterrows():\n",
    "    if pd.notnull(data.at[index,\"age\"]):\n",
    "        if pd.notnull(data.at[index,\"gender\"]):\n",
    "            data.at[index,\"gendered\"] = \"y\"\n",
    "            \n",
    "gendered = data[data[\"gendered\"] == \"y\"]\n",
    "not_gendered = data[data[\"gendered\"] == \"n\"]\n",
    "del gendered[\"gendered\"]\n",
    "del not_gendered[\"gendered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gendered = gendered[\"verdict\"]\n",
    "del gendered[\"verdict\"]\n",
    "X_gendered = gendered\n",
    "\n",
    "y_not_gendered = not_gendered[\"verdict\"]\n",
    "del not_gendered[\"verdict\"]\n",
    "X_not_gendered = not_gendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traindev_gendered, X_test_gendered, y_traindev_gendered, y_test_gendered = train_test_split(X_gendered, y_gendered, test_size=0.10, random_state=224)\n",
    "# Use these vvv\n",
    "X_train_gendered, X_dev_gendered, y_train_gendered, y_dev_gendered = train_test_split(X_traindev_gendered, y_traindev_gendered, test_size=0.1111, random_state=224)\n",
    "\n",
    "X_traindev_not_gendered, X_test_not_gendered, y_traindev_not_gendered, y_test_not_gendered = train_test_split(X_not_gendered, y_not_gendered, test_size=0.10, random_state=224)\n",
    "# Use these vvv\n",
    "X_train_not_gendered, X_dev_not_gendered, y_train_not_gendered, y_dev_not_gendered = train_test_split(X_traindev_not_gendered, y_traindev_not_gendered, test_size=0.1111, random_state=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_asshole</th>\n",
       "      <th>...</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>pos_neg</th>\n",
       "      <th>proper_nouns</th>\n",
       "      <th>cardinals</th>\n",
       "      <th>existential_there</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>question_words</th>\n",
       "      <th>negations</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96917</th>\n",
       "      <td>97004</td>\n",
       "      <td>97004</td>\n",
       "      <td>ew4izv</td>\n",
       "      <td>1.580386e+09</td>\n",
       "      <td>WIBTA for unfriending friends I have know for ...</td>\n",
       "      <td>I (f24) have always been friends with a close ...</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.087, 'neu': 0.844, 'pos': 0.068, 'co...</td>\n",
       "      <td>-0.8978</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>21.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56851</th>\n",
       "      <td>56934</td>\n",
       "      <td>56934</td>\n",
       "      <td>ctgh4m</td>\n",
       "      <td>1.566392e+09</td>\n",
       "      <td>AITA for expecting my partner to be ready when...</td>\n",
       "      <td>I (33M) have to pick up my partner (32F) a lot...</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.024, 'neu': 0.902, 'pos': 0.074, 'co...</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56090</th>\n",
       "      <td>56173</td>\n",
       "      <td>56173</td>\n",
       "      <td>crwpz6</td>\n",
       "      <td>1.566102e+09</td>\n",
       "      <td>AITA for saying no when my friend asked me to ...</td>\n",
       "      <td>I (27F) have a friend, let’s call him Jeff (29...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.131, 'neu': 0.782, 'pos': 0.087, 'co...</td>\n",
       "      <td>-0.9785</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>28.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86462</th>\n",
       "      <td>86549</td>\n",
       "      <td>86549</td>\n",
       "      <td>eej8mb</td>\n",
       "      <td>1.577099e+09</td>\n",
       "      <td>WIBTA if I ask my roommate to move out? I (26f...</td>\n",
       "      <td>\\n\\nWe have lived together for 2 months now a...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.771, 'pos': 0.109, 'co...</td>\n",
       "      <td>-0.8886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>23.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69428</th>\n",
       "      <td>69513</td>\n",
       "      <td>69513</td>\n",
       "      <td>dhsc23</td>\n",
       "      <td>1.571068e+09</td>\n",
       "      <td>WIBTA If I Didn't Go See My Ill Grandmother?</td>\n",
       "      <td>Just recently today (Thanksgiving here in Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.112, 'neu': 0.836, 'pos': 0.052, 'co...</td>\n",
       "      <td>-0.9526</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62186</th>\n",
       "      <td>62270</td>\n",
       "      <td>62270</td>\n",
       "      <td>d3cst3</td>\n",
       "      <td>1.568316e+09</td>\n",
       "      <td>AITA for backing out of getting an apartment w...</td>\n",
       "      <td>This has been gnawing at me for a while. Last ...</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.036, 'neu': 0.903, 'pos': 0.061, 'co...</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>21.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75680</th>\n",
       "      <td>75765</td>\n",
       "      <td>75765</td>\n",
       "      <td>du3z32</td>\n",
       "      <td>1.573344e+09</td>\n",
       "      <td>WIBTA for demanding my parents pay for my kitt...</td>\n",
       "      <td>I know it probably sounds super entitled but b...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.034, 'neu': 0.865, 'pos': 0.101, 'co...</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>16155</td>\n",
       "      <td>16155</td>\n",
       "      <td>avmiuy</td>\n",
       "      <td>1.551326e+09</td>\n",
       "      <td>AITA for asking my girlfriend to not go to a s...</td>\n",
       "      <td>So my girlfriend (22f) and I (22m) were talkin...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.058, 'neu': 0.835, 'pos': 0.107, 'co...</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>26.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82173</th>\n",
       "      <td>82260</td>\n",
       "      <td>82260</td>\n",
       "      <td>e7hsvc</td>\n",
       "      <td>1.575743e+09</td>\n",
       "      <td>AITA for not wanting to invite my dad to my we...</td>\n",
       "      <td>Backstory: My parents were divorced when I was...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.849, 'pos': 0.089, 'co...</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>16.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82339</th>\n",
       "      <td>82426</td>\n",
       "      <td>82426</td>\n",
       "      <td>e7q2ys</td>\n",
       "      <td>1.575784e+09</td>\n",
       "      <td>AITA for disciplining my nephew?</td>\n",
       "      <td>I (28M) have a darling little nephew (4M). Som...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.05, 'neu': 0.874, 'pos': 0.075, 'com...</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>12.274510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1      id     timestamp  \\\n",
       "96917       97004         97004  ew4izv  1.580386e+09   \n",
       "56851       56934         56934  ctgh4m  1.566392e+09   \n",
       "56090       56173         56173  crwpz6  1.566102e+09   \n",
       "86462       86549         86549  eej8mb  1.577099e+09   \n",
       "69428       69513         69513  dhsc23  1.571068e+09   \n",
       "...           ...           ...     ...           ...   \n",
       "62186       62270         62270  d3cst3  1.568316e+09   \n",
       "75680       75765         75765  du3z32  1.573344e+09   \n",
       "16086       16155         16155  avmiuy  1.551326e+09   \n",
       "82173       82260         82260  e7hsvc  1.575743e+09   \n",
       "82339       82426         82426  e7q2ys  1.575784e+09   \n",
       "\n",
       "                                                   title  \\\n",
       "96917  WIBTA for unfriending friends I have know for ...   \n",
       "56851  AITA for expecting my partner to be ready when...   \n",
       "56090  AITA for saying no when my friend asked me to ...   \n",
       "86462  WIBTA if I ask my roommate to move out? I (26f...   \n",
       "69428       WIBTA If I Didn't Go See My Ill Grandmother?   \n",
       "...                                                  ...   \n",
       "62186  AITA for backing out of getting an apartment w...   \n",
       "75680  WIBTA for demanding my parents pay for my kitt...   \n",
       "16086  AITA for asking my girlfriend to not go to a s...   \n",
       "82173  AITA for not wanting to invite my dad to my we...   \n",
       "82339                   AITA for disciplining my nephew?   \n",
       "\n",
       "                                                    body  edited  score  \\\n",
       "96917  I (f24) have always been friends with a close ...       0    109   \n",
       "56851  I (33M) have to pick up my partner (32F) a lot...       0    110   \n",
       "56090  I (27F) have a friend, let’s call him Jeff (29...       0     23   \n",
       "86462   \\n\\nWe have lived together for 2 months now a...       0      3   \n",
       "69428  Just recently today (Thanksgiving here in Cana...       0     11   \n",
       "...                                                  ...     ...    ...   \n",
       "62186  This has been gnawing at me for a while. Last ...       0    118   \n",
       "75680  I know it probably sounds super entitled but b...       0      3   \n",
       "16086  So my girlfriend (22f) and I (22m) were talkin...       1      3   \n",
       "82173  Backstory: My parents were divorced when I was...       0      3   \n",
       "82339  I (28M) have a darling little nephew (4M). Som...       0      5   \n",
       "\n",
       "       num_comments  is_asshole  ...  \\\n",
       "96917          31.0           0  ...   \n",
       "56851          72.0           0  ...   \n",
       "56090          16.0           0  ...   \n",
       "86462          14.0           0  ...   \n",
       "69428          12.0           0  ...   \n",
       "...             ...         ...  ...   \n",
       "62186          33.0           0  ...   \n",
       "75680          29.0           1  ...   \n",
       "16086          31.0           0  ...   \n",
       "82173          12.0           0  ...   \n",
       "82339          22.0           0  ...   \n",
       "\n",
       "                                                  scores  compound pos_neg  \\\n",
       "96917  {'neg': 0.087, 'neu': 0.844, 'pos': 0.068, 'co...   -0.8978       0   \n",
       "56851  {'neg': 0.024, 'neu': 0.902, 'pos': 0.074, 'co...    0.8900       1   \n",
       "56090  {'neg': 0.131, 'neu': 0.782, 'pos': 0.087, 'co...   -0.9785       0   \n",
       "86462  {'neg': 0.121, 'neu': 0.771, 'pos': 0.109, 'co...   -0.8886       0   \n",
       "69428  {'neg': 0.112, 'neu': 0.836, 'pos': 0.052, 'co...   -0.9526       0   \n",
       "...                                                  ...       ...     ...   \n",
       "62186  {'neg': 0.036, 'neu': 0.903, 'pos': 0.061, 'co...    0.9267       1   \n",
       "75680  {'neg': 0.034, 'neu': 0.865, 'pos': 0.101, 'co...    0.9599       1   \n",
       "16086  {'neg': 0.058, 'neu': 0.835, 'pos': 0.107, 'co...    0.9616       1   \n",
       "82173  {'neg': 0.062, 'neu': 0.849, 'pos': 0.089, 'co...    0.8986       1   \n",
       "82339  {'neg': 0.05, 'neu': 0.874, 'pos': 0.075, 'com...    0.9158       1   \n",
       "\n",
       "      proper_nouns  cardinals  existential_there  personal_pronouns  \\\n",
       "96917            4         12                  0                 47   \n",
       "56851            3          9                  1                 26   \n",
       "56090           24          4                  0                 62   \n",
       "86462            2         13                  1                100   \n",
       "69428            7          7                  0                 38   \n",
       "...            ...        ...                ...                ...   \n",
       "62186            6          7                  0                 60   \n",
       "75680            2          3                  0                 27   \n",
       "16086            3          2                  0                 46   \n",
       "82173            8          7                  0                 47   \n",
       "82339           33          5                  0                 56   \n",
       "\n",
       "       question_words  negations  sentence_length  \n",
       "96917               3          6        21.058824  \n",
       "56851               8          2        15.000000  \n",
       "56090               6          5        28.136364  \n",
       "86462               7         11        23.766667  \n",
       "69428               5         11        17.190476  \n",
       "...               ...        ...              ...  \n",
       "62186               5          4        21.482759  \n",
       "75680               0          5        18.928571  \n",
       "16086               3          8        26.800000  \n",
       "82173               6          7        16.681818  \n",
       "82339               4          9        12.274510  \n",
       "\n",
       "[934 rows x 23 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### End splitting\n",
    "len(X_train_not_gendered)\n",
    "X_dev_gendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "# For reporting stats!\n",
    "\n",
    "# All functions used for running regressions\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Pass in names of vars to select, returns reduced versions of the x's\n",
    "def selectVars(x_train, x_test, var_names):\n",
    "    x_train_new = x_train[var_names]\n",
    "    x_test_new = x_test[var_names]\n",
    "    return x_train_new, x_test_new\n",
    "\n",
    "# Get all variable names from df, except for verdict\n",
    "def getVariables(df):\n",
    "    features = list(data.columns)\n",
    "    features.remove('verdict')\n",
    "    return features\n",
    "\n",
    "# Takes the datasets, returns predictions and model\n",
    "def runRegression(x_train, y_train, x_test, y_test):\n",
    "    # Create and fit model\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(x_train, y_train)\n",
    "    # Get predictions\n",
    "    y_pred = logreg.predict(x_test)\n",
    "    return y_pred, logreg # Returns predictions, then model\n",
    "def getAccuracy(logreg, x_test, y_test):\n",
    "    # Print out accuracy and other stats\n",
    "    #print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "    return logreg.score(x_test, y_test)\n",
    "def getClassification(y_test, y_pred):\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    return classification_report(y_test, y_pred)\n",
    "\n",
    "def getROCCurve(logreg, x_test, y_test, y_pred):\n",
    "    logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes x/y train and names of vars to test\n",
    "# Returns a dictionary with the features, and the various metrics plus a plot of ROC\n",
    "def runSingleRegression(x_train, x_test, y_train, y_test, var_names):\n",
    "    # Store the results of the run\n",
    "    results = {}\n",
    "    # Select only the variables\n",
    "    x_train, x_test = selectVars(x_train, x_test, var_names)\n",
    "    # Record the names of features included\n",
    "    results['features'] = list(x_train.columns)\n",
    "    # Run the regression\n",
    "    y_pred, logreg = runRegression(x_train, y_train, x_test, y_test)\n",
    "    # get some of the stats\n",
    "    results['accuracy'] = getAccuracy(logreg, x_test, y_test)\n",
    "    results['metrics'] = getClassification(y_test, y_pred)\n",
    "    #results['roc'] = getROCCurve(logreg, x_test, y_test, y_pred)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablated models, without each feature individually\n",
    "def tryAllFeatures(x_train, x_test, y_train, y_test, features_list):\n",
    "    # Store regression results\n",
    "    all_regressions = {}\n",
    "    # Get all the features\n",
    "    #all_features = list(x_train.columns)\n",
    "    # For each feature, train a logistic regression without it\n",
    "    for i in range(0, len(features_list)):\n",
    "        # Drop one variable\n",
    "        variables = features_list[0:i] + features_list[(i+1):] # maybe\n",
    "        print(variables)\n",
    "        print(len(variables))\n",
    "        all_regressions[features_list[i]] = runSingleRegression(x_train, x_test, y_train, y_test, variables)\n",
    "    # Train one regression \n",
    "    all_regressions['full'] = runSingleRegression(x_train, x_test, y_train, y_test, features_list)\n",
    "    return all_regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find actual good logistic regression\n",
    "\n",
    "# Add one that uses gender and another that doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_feats = list(X_train_not_gendered.columns)\n",
    "#X_train_not_gendered\n",
    "# Select: 'edited' 'score' 'num_comments' 'is_asshole' 'compound' 'pos_neg', 'proper_nouns' 'cardinals' 'existential_there' 'personal_pronouns' 'question_words' 'negations' 'sentence_length' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'existential_there', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'personal_pronouns', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'question_words', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'negations', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'sentence_length']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edited', 'score', 'num_comments', 'compound', 'pos_neg', 'proper_nouns', 'cardinals', 'existential_there', 'personal_pronouns', 'question_words', 'negations']\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Full list of variables to use in train:\n",
    "x_features_list = ['edited','score','num_comments','compound','pos_neg', 'proper_nouns','cardinals','existential_there','personal_pronouns','question_words','negations','sentence_length'] \n",
    "\n",
    "all_regressions = tryAllFeatures(X_train_not_gendered, X_dev_not_gendered, y_train_not_gendered, y_dev_not_gendered, x_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edited': {'features': ['score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6117913832199546,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.58      0.04      0.07      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.30      0.26      0.21      8820\\n    weighted avg       0.50      0.61      0.48      8820\\n'},\n",
       " 'score': {'features': ['edited',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6073696145124716,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.20      0.00      0.00      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      1.00      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.20      0.25      0.19      8820\\n    weighted avg       0.41      0.61      0.46      8820\\n'},\n",
       " 'num_comments': {'features': ['edited',\n",
       "   'score',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6077097505668935,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.00      0.00      0.00      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      1.00      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.15      0.25      0.19      8820\\n    weighted avg       0.37      0.61      0.46      8820\\n'},\n",
       " 'compound': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6109977324263038,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.54      0.04      0.07      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.29      0.26      0.21      8820\\n    weighted avg       0.49      0.61      0.47      8820\\n'},\n",
       " 'pos_neg': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6117913832199546,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.57      0.04      0.07      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.30      0.26      0.21      8820\\n    weighted avg       0.50      0.61      0.48      8820\\n'},\n",
       " 'proper_nouns': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6113378684807256,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.54      0.04      0.07      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.29      0.26      0.21      8820\\n    weighted avg       0.49      0.61      0.48      8820\\n'},\n",
       " 'cardinals': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6111111111111112,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.56      0.03      0.06      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.29      0.26      0.20      8820\\n    weighted avg       0.49      0.61      0.47      8820\\n'},\n",
       " 'existential_there': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.611904761904762,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.60      0.03      0.06      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.30      0.26      0.21      8820\\n    weighted avg       0.50      0.61      0.47      8820\\n'},\n",
       " 'personal_pronouns': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6111111111111112,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.58      0.03      0.06      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.30      0.26      0.20      8820\\n    weighted avg       0.50      0.61      0.47      8820\\n'},\n",
       " 'question_words': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6117913832199546,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.56      0.04      0.08      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.29      0.26      0.21      8820\\n    weighted avg       0.49      0.61      0.48      8820\\n'},\n",
       " 'negations': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6115646258503401,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.57      0.04      0.07      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.30      0.26      0.21      8820\\n    weighted avg       0.50      0.61      0.48      8820\\n'},\n",
       " 'sentence_length': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations'],\n",
       "  'accuracy': 0.6104308390022676,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.52      0.04      0.07      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.28      0.26      0.21      8820\\n    weighted avg       0.49      0.61      0.47      8820\\n'},\n",
       " 'full': {'features': ['edited',\n",
       "   'score',\n",
       "   'num_comments',\n",
       "   'compound',\n",
       "   'pos_neg',\n",
       "   'proper_nouns',\n",
       "   'cardinals',\n",
       "   'existential_there',\n",
       "   'personal_pronouns',\n",
       "   'question_words',\n",
       "   'negations',\n",
       "   'sentence_length'],\n",
       "  'accuracy': 0.6117913832199546,\n",
       "  'metrics': '                  precision    recall  f1-score   support\\n\\n         asshole       0.59      0.03      0.06      1925\\n  everyone sucks       0.00      0.00      0.00       498\\nno assholes here       0.00      0.00      0.00      1037\\n not the asshole       0.61      0.99      0.76      5360\\n\\n        accuracy                           0.61      8820\\n       macro avg       0.30      0.26      0.21      8820\\n    weighted avg       0.50      0.61      0.47      8820\\n'}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
